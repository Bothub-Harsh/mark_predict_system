# Train model
model = LinearRegression()
model.fit(X, y)

# Slope tells how much output changes when input increases by 1
# Intercept = value when input = 0

Inside model.fit(X, y)

Step 1 â€” Read data
X = Hours studied
y = Marks obtained


Model sees points like:

(1,20) (2,30) (3,45) (5,70)

Step 2 â€” Try many lines
Computer imagines different equations:
Marks = 5Ã—Hours + 10   âŒ bad fit
Marks = 20Ã—Hours - 5   âŒ bad fit
Marks = 12Ã—Hours + 6   ğŸ‘ better
Marks = 12.5Ã—Hours +5  â­ best

Step 3 â€” Measure error

For every line it calculates mistake:

Example:

Real marks = 45
Predicted = 40
Error = 25

Goal:

Find line with minimum total error

This is called:

Least Squares Method

Step 4 â€” Choose best line

Finally sklearn stores:

model.coef_      # slope (m)
model.intercept_ # intercept (c)


Your model is now trained

Step 5 â€” Ready for prediction

Now:

model.predict([[6]])


No learning happens now âŒ
Only calculation happens âœ”ï¸

---------------

fit() = learning phase ğŸ§ 
predict() = using knowledge ğŸ“Š

pickle converts Python object â†’ bytes â†’ saves to file

LinearRegression object
(with slope & intercept learned)
â†“
converted to binary
â†“
stored in model.pkl
